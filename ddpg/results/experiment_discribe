实验描述：
实验01：在上一个版本的基础上将网络规模扩大到原始的3倍(times=3) 实验结果：成功,效果更好
实验02,在实验01(cu01:af74112)的基础上加入论文使用的权值初始化方法 实验结果:失败, 效果变差收敛变慢
实验03：在实验01的基础上去掉奖励值的归一化 实验结果：成功,相当于放大loss或者是增大学习率，收敛更快性能可以接受
实验04：在实验03的基础使用swish替换relu 实验结果：失败,效果不如relu
实验05：在实验03的基础上加入探索噪音收敛 实验结果:失败,误差抖动还是很厉害,不如原有的策略,按照输出来控制噪音大小
实验06：在实验03的基础上使用奖励归一化缩小最大值为4k 实验结果：没有明显变化